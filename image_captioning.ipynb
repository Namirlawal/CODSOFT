{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 13981,
     "status": "ok",
     "timestamp": 1721133085316,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "SGnLjAUYhjiv"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries and dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout, Add\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1721133496797,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "z4XVGz79hzxG"
   },
   "outputs": [],
   "source": [
    "#Features Extraction using ResNet50\n",
    "def extract_features(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    features = model.predict(image)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6242,
     "status": "ok",
     "timestamp": 1721133559092,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "PLsSnWx0jQ0Q",
    "outputId": "c9cf0498-ae58-4638-e5e4-f20b1fb61875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet50 model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1721133638792,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "K9-VLqyKjhH1"
   },
   "outputs": [],
   "source": [
    "#Prepare the Captioning Model\n",
    "def create_captioning_model(vocab_size, max_length):\n",
    "    # Feature extractor model\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    # Sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "\n",
    "    # Decoder model\n",
    "    decoder1 = Add()([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "    # Tie it together\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1619,
     "status": "ok",
     "timestamp": 1721133706151,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "cc1GCngnjzXn"
   },
   "outputs": [],
   "source": [
    "# Define necessary variables\n",
    "vocab_size = 5000  # Example vocab size\n",
    "max_length = 34  # Example max sequence length\n",
    "\n",
    "# Create the model\n",
    "captioning_model = create_captioning_model(vocab_size, max_length)\n",
    "captioning_model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1721133823097,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "Katon-_AkExS"
   },
   "outputs": [],
   "source": [
    "#Tokenize and Pad Captions (for training)\n",
    "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    for desc in desc_list:\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            out_seq = tf.keras.utils.to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            X1.append(photo)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1721133876889,
     "user": {
      "displayName": "NAMIR LAWAL",
      "userId": "16182051877242034676"
     },
     "user_tz": -60
    },
    "id": "m_6lelwDkg44"
   },
   "outputs": [],
   "source": [
    "# Captions (Inference)\n",
    "def generate_caption(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for _ in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = tokenizer.index_word[yhat]\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuxb0W7xkwr0"
   },
   "outputs": [],
   "source": [
    "# caption generation\n",
    "image_path = 'fulani cattle.jpg'\n",
    "photo = extract_features(image_path, resnet_model)\n",
    "caption = generate_caption(captioning_model, tokenizer, photo, max_length)\n",
    "print(caption)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMj3/S/NA+pmL0K7pXx+MGq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
